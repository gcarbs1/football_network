{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Network Creation from Football Pass Data**\n",
    "\n",
    "## **Objective**\n",
    "Create passing networks from football event data to analyze team performance and player interaction patterns.\n",
    "\n",
    "## **Steps**\n",
    "1. Load processed pass event data\n",
    "2. Create passing networks for each team in each match\n",
    "3. Calculate comprehensive network metrics\n",
    "4. Export network data for analysis\n",
    "\n",
    "## **Output**\n",
    "- Network summary with metrics for each team/match\n",
    "- Network edges (pass connections between players)\n",
    "- Player positions (average field positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Environment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.exception import AmbiguousSolution\n",
    "from networkx.algorithms import community as nx_comm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed event data...\n",
      "✓ Data loaded: 7,209,091 records\n",
      "\n",
      "Available columns: ['match_id', 'period', 'index', 'timestamp', 'type', 'team', 'team_id', 'player', 'player_id', 'pass_outcome', 'pass_recipient', 'pass_recipient_id', 'location_x', 'location_y', 'home_or_away', 'home_abbrev_name', 'away_abbrev_name', 'home_goals', 'away_goals', 'score_momentum', 'game_state', 'scoresheet', 'score_final', 'final_result']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"../data\")\n",
    "PROCESSED_DATA_PATH = DATA_PATH / \"processed\"\n",
    "\n",
    "print(\"Loading processed event data...\")\n",
    "events_df = pd.read_parquet(PROCESSED_DATA_PATH / \"events_processed.parquet\")\n",
    "print(f\"✓ Data loaded: {len(events_df):,} records\")\n",
    "print(f\"\\nAvailable columns: {events_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Event Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ On-ball events filtered: 2,016,542 records\n",
      "  Percentage of total: 28.0%\n",
      "\n",
      "Event type distribution:\n",
      "type\n",
      "Pass    2016542\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "PASS_EVENTS = ['Pass']\n",
    "\n",
    "pass_events = events_df[events_df['type'].isin(PASS_EVENTS)].copy()\n",
    "\n",
    "print(f\"✓ On-ball events filtered: {len(pass_events):,} records\")\n",
    "print(f\"  Percentage of total: {len(pass_events)/len(events_df)*100:.1f}%\")\n",
    "print(\"\\nEvent type distribution:\")\n",
    "print(pass_events['type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Network Construction Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_player_positions(pass_events: pd.DataFrame) -> pd.DataFrame:\n",
    "   player_positions = pass_events.groupby(\n",
    "       ['match_id', 'team', 'player_id', 'player']\n",
    "   ).agg({\n",
    "       'location_x': 'mean',\n",
    "       'location_y': 'mean',\n",
    "       'team_id': 'first',\n",
    "       'home_or_away': 'first',\n",
    "       'home_abbrev_name': 'first',\n",
    "       'away_abbrev_name': 'first',\n",
    "       'score_final': 'first',\n",
    "       'final_result': 'first'\n",
    "   }).reset_index()\n",
    "   \n",
    "   return player_positions\n",
    "\n",
    "\n",
    "def create_network_edges(pass_events: pd.DataFrame) -> pd.DataFrame:\n",
    "    network_edges = []\n",
    "    groups = pass_events.groupby(['match_id', 'team'])\n",
    "    \n",
    "    for (match_id, team), group in groups:\n",
    "        pass_counts = defaultdict(int)\n",
    "        player_total_passes = defaultdict(int)\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            if (pd.notna(row['player_id']) and \n",
    "                pd.notna(row['pass_recipient_id']) and \n",
    "                row['player_id'] != row['pass_recipient_id']):\n",
    "                \n",
    "                source = row['player_id']\n",
    "                target = row['pass_recipient_id']\n",
    "                \n",
    "                key = (source, target)\n",
    "                pass_counts[key] += 1\n",
    "                player_total_passes[source] += 1\n",
    "        \n",
    "        for (source, target), count in pass_counts.items():\n",
    "            total_by_source = player_total_passes[source]\n",
    "            weight = count / total_by_source if total_by_source > 0 else 0\n",
    "            network_edges.append({\n",
    "                'match_id': match_id,\n",
    "                'team': team,\n",
    "                'source_id': source,\n",
    "                'target_id': target,\n",
    "                'weight': weight\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(network_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Network Metrics Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_network_metrics(pass_events: pd.DataFrame, edges_df: pd.DataFrame, player_positions: pd.DataFrame) -> pd.DataFrame:\n",
    "    network_summaries = []\n",
    "    metric_funcs = [\n",
    "        calculate_basic_metrics,\n",
    "        calculate_centrality_metrics,\n",
    "        calculate_clustering_metrics,\n",
    "        calculate_spectral_metrics,\n",
    "        calculate_advanced_metrics\n",
    "    ]\n",
    "    groups = pass_events.groupby(['match_id', 'team'])\n",
    "    for (match_id, team), group in groups:\n",
    "        if group.empty:\n",
    "            continue\n",
    "        first = group.iloc[0]\n",
    "        metrics = {\n",
    "            'match_id': match_id,\n",
    "            'team': team,\n",
    "            'team_id': first.get('team_id'),\n",
    "            'home_or_away': first.get('home_or_away'),\n",
    "            'home_abbrev_name': first.get('home_abbrev_name'),\n",
    "            'away_abbrev_name': first.get('away_abbrev_name'),\n",
    "            'goal_in_match': check_goal_in_match(pass_events, match_id, team),\n",
    "            'score_final': get_match_final_score(pass_events, match_id),\n",
    "            'final_result': first.get('final_result'),\n",
    "            'edge_count': 0, 'network_density': 0,\n",
    "            'avg_in_degree': 0, 'std_in_degree': 0,\n",
    "            'avg_out_degree': 0, 'std_out_degree': 0,\n",
    "            'avg_betweenness': 0, 'std_betweenness': 0, 'max_betweenness': 0,\n",
    "            'avg_pagerank': 0, 'std_pagerank': 0,\n",
    "            'avg_eigenvector': 0, 'std_eigenvector': 0,\n",
    "            'avg_clustering': 0, 'std_clustering': 0,\n",
    "            'transitivity': 0, 'triangle_count': 0,\n",
    "            'reciprocity': 0, 'modularity': 0,\n",
    "            'num_cycles': 0,\n",
    "            'spectral_radius': 0, 'fiedler_value': 0,\n",
    "            'edge_weight_entropy': 0,\n",
    "            'avg_katz': 0, 'std_katz': 0,\n",
    "            'avg_harmonic_closeness': 0, 'std_harmonic_closeness': 0\n",
    "        }\n",
    "        team_edges = edges_df.query(\"match_id == @match_id and team == @team\")\n",
    "        pass_edges = team_edges[team_edges.source_id != team_edges.target_id]\n",
    "        if not pass_edges.empty:\n",
    "            G = nx.DiGraph()\n",
    "            players = player_positions.query(\"match_id == @match_id and team == @team\")\n",
    "            G.add_nodes_from(players['player_id'])\n",
    "            for _, e in pass_edges.iterrows():\n",
    "                G.add_edge(e.source_id, e.target_id, weight=e.weight)\n",
    "            for func in metric_funcs:\n",
    "                metrics.update(func(G))\n",
    "        network_summaries.append(metrics)\n",
    "    return pd.DataFrame(network_summaries)\n",
    "\n",
    "def check_goal_in_match(df: pd.DataFrame, match_id: int, team: str) -> bool:\n",
    "    team_data = df[(df['match_id'] == match_id) & (df['team'] == team)]\n",
    "    if team_data.empty:\n",
    "        return False\n",
    "    side = team_data['home_or_away'].iat[0]\n",
    "    goals = team_data['home_goals'] if side == 'HOME' else team_data['away_goals']\n",
    "    return (goals.max() - goals.min()) > 0\n",
    "\n",
    "def get_match_final_score(df: pd.DataFrame, match_id: int) -> str:\n",
    "    md = df[df['match_id'] == match_id]\n",
    "    if md.empty:\n",
    "        return \"0 x 0\"\n",
    "    if 'index' in md.columns and 'score_momentum' in md.columns:\n",
    "        last = md.loc[md['index'] == md['index'].max()]\n",
    "        if not last.empty:\n",
    "            return last['score_momentum'].iat[0]\n",
    "    return f\"{md['home_goals'].max()} x {md['away_goals'].max()}\"\n",
    "\n",
    "def calculate_basic_metrics(G: nx.DiGraph) -> Dict[str, float]:\n",
    "    m = {}\n",
    "    m['edge_count'] = G.number_of_edges()\n",
    "    m['network_density'] = nx.density(G)\n",
    "    in_deg = np.array([d for _, d in G.in_degree(weight='weight')])\n",
    "    out_deg = np.array([d for _, d in G.out_degree(weight='weight')])\n",
    "    if in_deg.size:\n",
    "        m['avg_in_degree'], m['std_in_degree'] = in_deg.mean(), in_deg.std()\n",
    "        m['avg_out_degree'], m['std_out_degree'] = out_deg.mean(), out_deg.std()\n",
    "    return m\n",
    "\n",
    "def calculate_centrality_metrics(G: nx.DiGraph) -> Dict[str, float]:\n",
    "    m = {}\n",
    "    bt = nx.betweenness_centrality(G, weight='weight', normalized=True)\n",
    "    vals = np.array(list(bt.values()))\n",
    "    if vals.size:\n",
    "        m['avg_betweenness'], m['std_betweenness'], m['max_betweenness'] = vals.mean(), vals.std(), vals.max()\n",
    "    pr = np.array(list(nx.pagerank(G, weight='weight').values()))\n",
    "    m['avg_pagerank'], m['std_pagerank'] = pr.mean(), pr.std()\n",
    "    Gu = G.to_undirected()\n",
    "    try:\n",
    "        ev = nx.eigenvector_centrality_numpy(Gu, weight='weight')\n",
    "    except nx.exception.AmbiguousSolution:\n",
    "        comps = list(nx.connected_components(Gu))\n",
    "        lc = max(comps, key=len)\n",
    "        ev_sub = nx.eigenvector_centrality_numpy(Gu.subgraph(lc), weight='weight')\n",
    "        ev = {n: ev_sub.get(n, 0) for n in Gu.nodes()}\n",
    "    evv = np.array(list(ev.values()))\n",
    "    m['avg_eigenvector'], m['std_eigenvector'] = evv.mean(), evv.std()\n",
    "    try:\n",
    "        kz = np.array(list(nx.katz_centrality_numpy(G, weight='weight', alpha=0.005).values()))\n",
    "        m['avg_katz'], m['std_katz'] = kz.mean(), kz.std()\n",
    "    except:\n",
    "        pass\n",
    "    hc = np.array(list(nx.harmonic_centrality(G).values()))\n",
    "    m['avg_harmonic_closeness'], m['std_harmonic_closeness'] = hc.mean(), hc.std()\n",
    "    return m\n",
    "\n",
    "def calculate_clustering_metrics(G: nx.DiGraph) -> Dict[str, float]:\n",
    "    m = {}\n",
    "    Gu = G.to_undirected()\n",
    "    cl = np.array(list(nx.clustering(Gu, weight='weight').values()))\n",
    "    if cl.size:\n",
    "        m['avg_clustering'], m['std_clustering'] = cl.mean(), cl.std()\n",
    "    m['transitivity'] = nx.transitivity(Gu)\n",
    "    tri = nx.triangles(Gu)\n",
    "    m['triangle_count'] = sum(tri.values()) // 3\n",
    "    m['reciprocity'] = nx.reciprocity(G) or 0\n",
    "    comms = list(nx_comm.greedy_modularity_communities(Gu, weight='weight'))\n",
    "    if comms:\n",
    "        m['modularity'] = nx_comm.modularity(Gu, comms, weight='weight')\n",
    "    m['num_cycles'] = len(nx.cycle_basis(Gu))\n",
    "    return m\n",
    "\n",
    "def calculate_spectral_metrics(G: nx.DiGraph) -> Dict[str, float]:\n",
    "    m = {}\n",
    "    Gu = G.to_undirected()\n",
    "    A = nx.to_numpy_array(Gu, weight='weight')\n",
    "    eigs = np.linalg.eigvals(A)\n",
    "    if eigs.size:\n",
    "        m['spectral_radius'] = float(np.max(np.abs(eigs)))\n",
    "    L = nx.normalized_laplacian_matrix(Gu, weight='weight').toarray()\n",
    "    lev = np.sort(np.linalg.eigvals(L))\n",
    "    if lev.size > 1:\n",
    "        m['fiedler_value'] = float(lev[1])\n",
    "    return m\n",
    "\n",
    "def calculate_advanced_metrics(G: nx.DiGraph) -> Dict[str, float]:\n",
    "    m = {}\n",
    "    weights = np.array([data['weight'] for _, _, data in G.edges(data=True)])\n",
    "    total = weights.sum()\n",
    "    if total > 0:\n",
    "        probs = weights / total\n",
    "        nz = probs[probs > 0]\n",
    "        m['edge_weight_entropy'] = float(-np.sum(nz * np.log2(nz)))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Network Creation Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Network creation completed!\n",
      "  Networks created: 4050\n",
      "  Total edges: 479129\n",
      "  Total player positions: 56979\n"
     ]
    }
   ],
   "source": [
    "def create_football_networks(pass_events: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "   player_positions = calculate_player_positions(pass_events)\n",
    "   network_edges = create_network_edges(pass_events)\n",
    "   network_summary = calculate_network_metrics(pass_events, network_edges, player_positions)\n",
    "   \n",
    "   return network_summary, network_edges, player_positions\n",
    "\n",
    "network_summary, network_edges, player_positions = create_football_networks(pass_events)\n",
    "\n",
    "print(\"\\n✓ Network creation completed!\")\n",
    "print(f\"  Networks created: {len(network_summary)}\")\n",
    "print(f\"  Total edges: {len(network_edges)}\")\n",
    "print(f\"  Total player positions: {len(player_positions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Data Preparation for Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Final result converted to binary format (Win=1, Loss=0)\n"
     ]
    }
   ],
   "source": [
    "network_summary['final_result'] = network_summary['final_result'].map({'W': 1, 'L': 0})\n",
    "print(\"✓ Final result converted to binary format (Win=1, Loss=0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Network Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NETWORK ANALYSIS ===\n",
      "\n",
      "Summary statistics for key network metrics:\n",
      "\n",
      "edge_count:\n",
      "  Mean: 118.3035\n",
      "  Median: 119.0000\n",
      "  Std Dev: 13.2752\n",
      "  Min: 61.0000\n",
      "  Max: 166.0000\n",
      "\n",
      "network_density:\n",
      "  Mean: 0.6403\n",
      "  Median: 0.6429\n",
      "  Std Dev: 0.0753\n",
      "  Min: 0.3250\n",
      "  Max: 0.8939\n",
      "\n",
      "avg_betweenness:\n",
      "  Mean: 0.0701\n",
      "  Median: 0.0694\n",
      "  Std Dev: 0.0090\n",
      "  Min: 0.0435\n",
      "  Max: 0.1106\n",
      "\n",
      "avg_pagerank:\n",
      "  Mean: 0.0710\n",
      "  Median: 0.0714\n",
      "  Std Dev: 0.0037\n",
      "  Min: 0.0588\n",
      "  Max: 0.0909\n",
      "\n",
      "avg_clustering:\n",
      "  Mean: 0.1660\n",
      "  Median: 0.1693\n",
      "  Std Dev: 0.0555\n",
      "  Min: 0.0567\n",
      "  Max: 0.3810\n",
      "\n",
      "transitivity:\n",
      "  Mean: 0.8303\n",
      "  Median: 0.8355\n",
      "  Std Dev: 0.0471\n",
      "  Min: 0.5899\n",
      "  Max: 0.9677\n",
      "\n",
      "\n",
      "Metrics comparison by match result:\n",
      "\n",
      "edge_count:\n",
      "  Wins - Mean: 117.1867, Std: 13.8986\n",
      "  Losses - Mean: 119.4202, Std: 12.5254\n",
      "\n",
      "network_density:\n",
      "  Wins - Mean: 0.6379, Std: 0.0785\n",
      "  Losses - Mean: 0.6426, Std: 0.0719\n",
      "\n",
      "avg_betweenness:\n",
      "  Wins - Mean: 0.0722, Std: 0.0092\n",
      "  Losses - Mean: 0.0680, Std: 0.0084\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== NETWORK ANALYSIS ===\")\n",
    "\n",
    "key_metrics = [\n",
    "    'edge_count', 'network_density', 'avg_betweenness', \n",
    "    'avg_pagerank', 'avg_clustering', 'transitivity'\n",
    "]\n",
    "\n",
    "print(\"\\nSummary statistics for key network metrics:\")\n",
    "for metric in key_metrics:\n",
    "    if metric in network_summary.columns:\n",
    "        values = network_summary[metric]\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(f\"  Mean: {values.mean():.4f}\")\n",
    "        print(f\"  Median: {values.median():.4f}\")\n",
    "        print(f\"  Std Dev: {values.std():.4f}\")\n",
    "        print(f\"  Min: {values.min():.4f}\")\n",
    "        print(f\"  Max: {values.max():.4f}\")\n",
    "\n",
    "print(\"\\n\\nMetrics comparison by match result:\")\n",
    "for metric in key_metrics[:3]:  \n",
    "    if metric in network_summary.columns:\n",
    "        wins = network_summary[network_summary['final_result'] == 1][metric]\n",
    "        losses = network_summary[network_summary['final_result'] == 0][metric]\n",
    "        print(f\"\\n{metric}:\")\n",
    "        print(f\"  Wins - Mean: {wins.mean():.4f}, Std: {wins.std():.4f}\")\n",
    "        print(f\"  Losses - Mean: {losses.mean():.4f}, Std: {losses.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Export Network Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXPORTING NETWORK DATA ===\n",
      "✓ Network summary saved to: ..\\data\\processed\\on_ball_networks.parquet\n",
      "  File size: 0.65 MB\n",
      "\n",
      "✓ Network edges saved to: ..\\data\\processed\\network_edges.parquet\n",
      "  File size: 2.27 MB\n",
      "\n",
      "✓ Player positions saved to: ..\\data\\processed\\player_positions.parquet\n",
      "  File size: 1.17 MB\n",
      "\n",
      "✓ All network data exported successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== EXPORTING NETWORK DATA ===\")\n",
    "\n",
    "networks_path = PROCESSED_DATA_PATH / \"on_ball_networks.parquet\"\n",
    "network_summary.to_parquet(networks_path, index=False)\n",
    "print(f\"✓ Network summary saved to: {networks_path}\")\n",
    "print(f\"  File size: {networks_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "edges_path = PROCESSED_DATA_PATH / \"network_edges.parquet\"\n",
    "network_edges.to_parquet(edges_path, index=False)\n",
    "print(f\"\\n✓ Network edges saved to: {edges_path}\")\n",
    "print(f\"  File size: {edges_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "positions_path = PROCESSED_DATA_PATH / \"player_positions.parquet\"\n",
    "player_positions.to_parquet(positions_path, index=False)\n",
    "print(f\"\\n✓ Player positions saved to: {positions_path}\")\n",
    "print(f\"  File size: {positions_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "print(\"\\n✓ All network data exported successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
